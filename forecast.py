#!/usr/bin/env python
# ==================================================================
# éœ€è¦äºˆæ¸¬ãƒ•ãƒ«ç‰ˆ 2025-07  â”€â”€ recency-weighted learning & accuracy log
# ==================================================================
import os, json, base64, re, unicodedata, logging, warnings
from datetime import date, timedelta, datetime
import numpy as np, pandas as pd, requests, gspread
from google.oauth2.service_account import Credentials
from catboost import CatBoostRegressor

# ---------- è¨­å®š ----------
SID          = os.getenv("GSHEET_ID")
SA_JSON      = os.getenv("GSPREAD_SA_JSON")
DB_SHEET     = os.getenv("DB_SHEET",      "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹")
FC_SHEET     = os.getenv("FORECAST_SHEET","éœ€è¦äºˆæ¸¬")
HIST_SHEET   = os.getenv("HISTORY_SHEET", "äºˆæ¸¬å±¥æ­´")   # new
METRIC_SHEET = os.getenv("METRIC_SHEET",  "äºˆæ¸¬ç²¾åº¦")   # new
FORECAST_D   = int(os.getenv("FORECAST_DAYS", 7))
LABEL_ROWS   = int(os.getenv("LABEL_ROWS", 10))
LAT, LON     = 36.3740, 140.5662

META_ROWS = ["æ›œæ—¥","å…­æ›œ","å¹´ä¸­è¡Œäº‹","å¤©æ°—","æœ€é«˜æ°—æ¸©","æœ€ä½Žæ°—æ¸©"]

logging.basicConfig(level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s")
warnings.filterwarnings("ignore", category=FutureWarning)

# ---------- util ----------
def creds():
    raw = SA_JSON or ""
    data = json.loads(raw) if raw.lstrip().startswith("{") \
           else json.loads(base64.b64decode(raw))
    return Credentials.from_service_account_info(
        data, scopes=["https://www.googleapis.com/auth/spreadsheets"])

def num_clean(s):
    return (pd.to_numeric(
        s.astype(str).str.replace(r"[^\d.\-]", "", regex=True)
         .str.replace("ï¼Ž", ".", regex=False)
         .replace("", np.nan),
        errors="coerce").fillna(0))

def norm(t):
    return re.sub(r"[ ã€€ã€ã€‘\[\]\(\)]", "",
                  unicodedata.normalize("NFKC", str(t))).lower()

def fuzzy_row(df, key):
    nk = norm(key)
    for r in df.index:
        if nk in norm(r):
            return r
    return None

def ensure_series(x):
    return x.iloc[0] if isinstance(x, pd.DataFrame) else x

W2C = {"å¿«æ™´":0,"æ™´":1,"è–„æ›‡":2,"æ›‡":3,"éœ§":45,"éœ§é›¨":51,"å°é›¨":61,"é›¨":63,
       "å¤§é›¨":65,"å°é›ª":71,"é›ª":73,"å¤§é›ª":75,"ã«ã‚ã‹é›¨":80,"é›·é›¨":95,
       "â€”":np.nan,"ï½°":np.nan,"":np.nan}

def weather_forecast(days):
    url = (f"https://api.open-meteo.com/v1/forecast?"
           f"latitude={LAT}&longitude={LON}"
           "&daily=weathercode,temperature_2m_max,temperature_2m_min"
           "&timezone=Asia%2FTokyo")
    d = requests.get(url, timeout=10).json()["daily"]
    return (pd.DataFrame({
        "dt":   pd.to_datetime(d["time"]),
        "code": d["weathercode"],
        "tmax": d["temperature_2m_max"],
        "tmin": d["temperature_2m_min"],
    }).set_index("dt").iloc[:days])

ROKUYO = ["å…ˆå‹","å‹å¼•","å…ˆè² ","ä»æ»…","å¤§å®‰","èµ¤å£"]
def rokuyo(start, days):
    base = datetime(1900,1,1)
    return [ROKUYO[((start+timedelta(i))-base.date()).days % 6] for i in range(days)]

# ---------- ãƒ¢ãƒ‡ãƒ«ï¼ˆæœ€è¿‘ãƒ‡ãƒ¼ã‚¿é‡ã¿ â†‘ï¼‰ ----------
def cat_predict(y: pd.Series,
                X_extra: pd.DataFrame,
                Xf_extra: pd.DataFrame) -> np.ndarray:
    y = ensure_series(y).astype(float)
    idx = y.dropna().index
    if idx.empty or float(y.sum()) == 0:
        return np.zeros(len(Xf_extra))

    # --- åŸºæœ¬ç‰¹å¾´
    X  = pd.DataFrame(index=idx)
    Xf = pd.DataFrame(index=Xf_extra.index)
    X["dow"] = idx.weekday.astype(int)
    X["mon"] = idx.month.astype(int)
    X["doy"] = idx.dayofyear.astype(int)
    Xf["dow"] = Xf.index.weekday.astype(int)
    Xf["mon"] = Xf.index.month.astype(int)
    Xf["doy"] = Xf.index.dayofyear.astype(int)

    X  = X.join(X_extra.reindex(idx))
    Xf = Xf.join(Xf_extra)

    # ----------â˜… recency-weight ----------
    span = (idx.max() - idx.min()).days or 1
    w = 1 + (idx - idx.min()).days / span      # 1.0ã€œ2.0 ç·šå½¢ã‚¦ã‚§ã‚¤ãƒˆ
    # ------------------------------------

    model = CatBoostRegressor(
        depth=8, learning_rate=0.1,
        loss_function="RMSE", random_state=42,
        verbose=False)
    model.fit(X, y.loc[idx], sample_weight=w, cat_features=["dow","mon"])
    return np.clip(model.predict(Xf), 0, None)

# ---------- main ----------
def main():
    gc  = gspread.authorize(creds())
    sh  = gc.open_by_key(SID)

    # --- ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹èª­ã¿è¾¼ã¿
    df0 = pd.DataFrame(sh.worksheet(DB_SHEET).get_all_values())
    df0.columns; df = df0.drop(0)
    df.columns = df0.iloc[0]

    dates = pd.to_datetime(df.columns[1:], errors="coerce")
    wide  = df.set_index(df.columns[0]).iloc[:, ~dates.isna()]
    wide.columns = dates[~dates.isna()]
    wide = wide.apply(num_clean, axis=1)

    # --- è¡Œã‚’ç‰¹å®š
    r_sales = fuzzy_row(wide, "å£²ä¸Š");  r_cust  = fuzzy_row(wide, "å®¢æ•°")
    r_unit  = fuzzy_row(wide, "å®¢å˜ä¾¡"); r_tmax  = fuzzy_row(wide, "æœ€é«˜æ°—æ¸©")
    r_tmin  = fuzzy_row(wide, "æœ€ä½Žæ°—æ¸©"); r_wtxt = fuzzy_row(wide, "å¤©æ°—")

    wcode_hist = wide.loc[r_wtxt].replace(W2C).astype(float) if r_wtxt else pd.Series(index=wide.columns, dtype=float)

    # --- æœªæ¥å¤–ç”Ÿ
    start   = date.today()+timedelta(1)
    fut_idx = pd.date_range(start, periods=FORECAST_D)
    wdf     = weather_forecast(FORECAST_D).reindex(fut_idx, method="nearest")

    Xf_extra = pd.DataFrame({
        "code": wdf["code"].astype(float),
        "tmax": wdf["tmax"].astype(float),
        "tmin": wdf["tmin"].astype(float)
    }, index=fut_idx)

    X_extra = pd.DataFrame({
        "code": wcode_hist,
        "tmax": ensure_series(wide.loc[r_tmax]) if r_tmax else np.nan,
        "tmin": ensure_series(wide.loc[r_tmin]) if r_tmin else np.nan
    })

    # --- äºˆæ¸¬
    agg_lbls = ["å£²ä¸Š","å®¢æ•°","å®¢å˜ä¾¡"];    agg_rows = [r_sales, r_cust, r_unit]
    item_rows = [r for r in wide.index
                 if r not in META_ROWS+agg_lbls and not norm(r).startswith("å¤©æ°—")]
    labels = agg_lbls + item_rows;       rows = agg_rows + item_rows
    preds  = {l: cat_predict(wide.loc[r], X_extra, Xf_extra) for l,r in zip(labels,rows)}

    # ---------- 1) éœ€è¦äºˆæ¸¬ã‚·ãƒ¼ãƒˆä¸€æ‹¬æ›´æ–° ----------
    ws = sh.worksheet(FC_SHEET) if FC_SHEET in [w.title for w in sh.worksheets()] \
         else sh.add_worksheet(FC_SHEET, rows=2000, cols=400)
    ws.resize(rows=LABEL_ROWS+len(labels), cols=1+FORECAST_D)

    header = [["æ—¥ä»˜"]+[d.strftime("%Y/%m/%d") for d in fut_idx]]
    meta   = [
        ["æ›œæ—¥"] + ["æœˆç«æ°´æœ¨é‡‘åœŸæ—¥"[d.weekday()] for d in fut_idx],
        ["å…­æ›œ"] + rokuyo(start, FORECAST_D),
        ["å¹´ä¸­è¡Œäº‹"] + [""]*FORECAST_D,
        ["å¤©æ°—"] + wdf["code"].map({
            0:"å¿«æ™´",1:"æ™´",2:"è–„æ›‡",3:"æ›‡",45:"éœ§",51:"éœ§é›¨",61:"å°é›¨",
            63:"é›¨",65:"å¤§é›¨",71:"é›ª",75:"å¤§é›ª",80:"ã«ã‚ã‹é›¨",95:"é›·é›¨"}).fillna("ï¼").tolist(),
        ["æœ€é«˜æ°—æ¸©"] + wdf["tmax"].round(1).tolist(),
        ["æœ€ä½Žæ°—æ¸©"] + wdf["tmin"].round(1).tolist()
    ]
    ws.update(range_name="A1", values=header+meta)

    body=[]
    for lbl in labels:
        arr = preds[lbl]
        body.append([lbl]+(arr.round(1) if lbl in agg_lbls
                           else arr.round().astype(int)).tolist())
    ws.update(range_name=f"A{LABEL_ROWS+1}", values=body)

    # ---------- 2) äºˆæ¸¬å±¥æ­´ã‚·ãƒ¼ãƒˆã«è¿½è¨˜ ----------
    hist_ws = sh.worksheet(HIST_SHEET) if HIST_SHEET in [w.title for w in sh.worksheets()] \
              else sh.add_worksheet(HIST_SHEET, rows=1, cols=5)
    if hist_ws.row_count == 0:
        hist_ws.update("A1", [["run_date","target_date","label","pred"]])

    run_date = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    append_rows = []
    for lbl in labels:
        for td, val in zip(fut_idx, preds[lbl]):
            append_rows.append([run_date, td.strftime("%Y-%m-%d"), lbl, float(val)])
    hist_ws.append_rows(append_rows, value_input_option="USER_ENTERED")

    # ---------- 3) ç²¾åº¦ãƒ¬ãƒãƒ¼ãƒˆ (å®Ÿç¸¾ vs äºˆæ¸¬) ----------
    #   æ˜¨æ—¥ä»¥å‰ã§ã€å±¥æ­´ + å®Ÿç¸¾ã©ã¡ã‚‰ã‚‚ã‚ã‚‹è¡Œã®ã¿è©•ä¾¡
    hist_df = pd.DataFrame(hist_ws.get_all_values()[1:], columns=["run","target","label","pred"])
    hist_df["target"] = pd.to_datetime(hist_df["target"])
    hist_df["pred"]   = pd.to_numeric(hist_df["pred"], errors="coerce")
    actual_map = wide.to_dict(orient="index")  # labelâ†’Series
    records=[]
    cutoff = date.today()                      # ä»Šæ—¥ã‚ˆã‚Šå‰ãŒè©•ä¾¡å¯¾è±¡
    for _, r in hist_df.iterrows():
        if r["target"].date() >= cutoff: continue
        lab = r["label"]; d = r["target"]
        if lab in actual_map and d in actual_map[lab]:
            act = actual_map[lab][d]
            if pd.notna(act):
                err = abs(act - r["pred"])
                ape = err / act * 100 if act else np.nan
                records.append([lab, err, ape])
    if records:
        res = pd.DataFrame(records, columns=["label","ae","ape"])
        report = (res.groupby("label")
                       .agg(MAE=("ae","mean"), MAPE=("ape","mean"))
                       .reset_index())
        met_ws = sh.worksheet(METRIC_SHEET) if METRIC_SHEET in [w.title for w in sh.worksheets()] \
                 else sh.add_worksheet(METRIC_SHEET, rows=2000, cols=10)
        met_ws.clear()
        met_ws.update("A1", [report.columns.tolist()]+report.round(2).values.tolist())

    logging.info("âœ… å®Œäº† â€” forecast / history / metric æ›´æ–°OK")

if __name__ == "__main__":
    try:
        main()
    except Exception:
        logging.exception("ðŸš¨ Fatal")
